{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e43f9",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad5224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0') #先調1再調0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0994207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe6f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(1000, 6724)\n",
    "x=x.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8c68f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "data_in=np.loadtxt('./data/preserved/input_div_U_2.dat')\n",
    "data_out=np.loadtxt('./data/preserved/output_P.dat')\n",
    "x=torch.Tensor(data_in)\n",
    "y=torch.Tensor(data_out)\n",
    "x=x.to(device)\n",
    "y=y.to(device)\n",
    "x=x[:8000]\n",
    "y=y[:8000]\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(TensorDataset(x, y), batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c5516",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create model 建立model習慣建立class\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, B, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear_1=torch.nn.Linear(D_in, H)\n",
    "        self.linear_2=torch.nn.Linear(H, B)\n",
    "        self.linear_3=torch.nn.Linear(B, D_out)\n",
    "    \n",
    "    # Step 3. Forward pass-1/2    # Step 4. Backward pass-1/2\n",
    "    def forward(self, x):\n",
    "        h=self.linear_1(x)\n",
    "        h_relu=torch.nn.functional.relu(h) #為何activation and hidden layer 的實現方式不同\n",
    "        b=self.linear_2(h_relu) \n",
    "        b_relu=torch.nn.functional.relu(b)\n",
    "        y_pred=self.linear_3(b_relu) \n",
    "        return y_pred\n",
    "    \n",
    "model= TwoLayerNet(D_in=6400, H=1000, B=1000, D_out=6400)\n",
    "model=model.to(device) #這行是什麼意思? A:将模型加载到相应的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.nn.Sequential(torch.nn.Unflatten(1, (1,82,82)))(x)\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, channel_1, channel_2, kernel_dim):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, channel_1, kernel_dim)\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_dim)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(78*78*3, 1000)  # 78*78 from image dimension\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 6724)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet(channel_1=3, channel_2=3, kernel_dim=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3229b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol=1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42a038",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687717dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f15f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epoch=[]\n",
    "loss_values = []\n",
    "loss=1\n",
    "epochs=0\n",
    "\n",
    "print(\"Epochs    Loss\")\n",
    "\n",
    "while(loss>tol):\n",
    "    epochs=epochs+1\n",
    "    scheduler.step()\n",
    "    \n",
    "    for x_batch, y_batch in loader:\n",
    "        # Forward pass\n",
    "        y_pred=model(x_batch)\n",
    "        loss=torch.nn.functional.mse_loss(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    loss_epoch.append(epochs)\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if epochs%1==0:\n",
    "        print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "        \n",
    "    loss=loss.item()\n",
    "\n",
    "print(epochs, \"    \", loss.item())\n",
    "\n",
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9dbba",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d43359",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "model=model.to(device)\n",
    "PATH= \"model_jit_E.pth\"\n",
    "traced_net=torch.jit.trace(model, (torch.randn(1,6400).to(torch.float64)).to(device))\n",
    "traced_net.to(torch.float64)\n",
    "torch.jit.save(traced_net, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
