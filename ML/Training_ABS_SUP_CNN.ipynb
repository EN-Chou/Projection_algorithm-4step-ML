{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e43f9",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device check(CFDLab)\n",
    "device=torch.device('cuda:1') #先調1再調0\n",
    "print(torch.cuda.is_available())\n",
    "x=torch.randn(100).to(device) # Gives warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a358a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0') # Fix warning\n",
    "x=torch.randn(100).to(device) # No warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34dbfa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# device check(my pc)\n",
    "device=torch.device('cuda')\n",
    "print(torch.cuda.is_available())\n",
    "x=torch.randn(100).to(device) # No warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262401a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b237a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=100 #batchsize\n",
    "opt=1 # optimizer\n",
    "tol=1e-3 # tolerance\n",
    "ch=[1, 3, 3, 3, 3, 1] #model layout\n",
    "pad=[0, 0, 0, 0, 0]\n",
    "PATH= \"ABS_SUP_CNN_TEST\" # model name, saved as.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8c68f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1157f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "data_in=np.loadtxt('./data/preserved/input_div_U_2_1s.dat')\n",
    "data_out=np.loadtxt('./data/preserved/output_P_1s.dat')\n",
    "x_in=torch.Tensor(data_in)\n",
    "y_in=torch.Tensor(data_out)\n",
    "x_in=x_in.to(device)\n",
    "y_in=y_in.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849bbccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 6400])\n",
      "torch.Size([1000, 6400])\n"
     ]
    }
   ],
   "source": [
    "x=x_in\n",
    "y=y_in\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b439a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(TensorDataset(x, y), batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c5516",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534a75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, channel_1, channel_2, channel_3, channel_4, channel_5, kernel_dim):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, channel_1, kernel_dim, padding=pad[0])\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_dim, padding=pad[1])\n",
    "        self.conv3 = nn.Conv2d(channel_2, channel_3, kernel_dim, padding=pad[2])\n",
    "        self.conv4 = nn.Conv2d(channel_3, channel_4, kernel_dim, padding=pad[3])\n",
    "        self.conv5 = nn.Conv2d(channel_4, channel_5, kernel_dim, padding=pad[4])\n",
    "        # an affine operation: y = Wx + b\n",
    "        lin_d=80-(pad[0]+pad[1]+pad[2]+pad[3]+pad[4])*2\n",
    "        self.fc1 = nn.Linear(70*70*channel_5, 6400)  # 78*78 from image dimension\n",
    "        #self.fc2 = nn.Linear(1000, 1000)\n",
    "        #self.fc3 = nn.Linear(1000, 6400)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet(channel_1=ch[1], channel_2=ch[2], channel_3=ch[3], channel_4=ch[4], channel_5=1, kernel_dim=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42a038",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687717dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt==0:\n",
    "    optimizer=torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "elif opt==1:\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d34a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs    Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enchou/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  1 ; Loss:  0.06607778370380402\n",
      "Epochs:  2 ; Loss:  0.061265502125024796\n",
      "Epochs:  3 ; Loss:  0.05669865012168884\n",
      "Epochs:  4 ; Loss:  0.052390243858098984\n",
      "Epochs:  5 ; Loss:  0.0483425110578537\n",
      "Epochs:  6 ; Loss:  0.04455103725194931\n",
      "Epochs:  7 ; Loss:  0.041007835417985916\n",
      "Epochs:  8 ; Loss:  0.03770318254828453\n",
      "Epochs:  9 ; Loss:  0.03462662547826767\n",
      "Epochs:  10 ; Loss:  0.031767457723617554\n",
      "Epochs:  11 ; Loss:  0.029114950448274612\n",
      "Epochs:  12 ; Loss:  0.026658471673727036\n",
      "Epochs:  13 ; Loss:  0.024387527257204056\n",
      "Epochs:  14 ; Loss:  0.022291820496320724\n",
      "Epochs:  15 ; Loss:  0.020361263304948807\n",
      "Epochs:  16 ; Loss:  0.018586013466119766\n",
      "Epochs:  17 ; Loss:  0.01695648394525051\n",
      "Epochs:  18 ; Loss:  0.015463382937014103\n",
      "Epochs:  19 ; Loss:  0.014097713865339756\n",
      "Epochs:  20 ; Loss:  0.012850799597799778\n",
      "Epochs:  21 ; Loss:  0.011714297346770763\n",
      "Epochs:  22 ; Loss:  0.010680215433239937\n",
      "Epochs:  23 ; Loss:  0.009740914218127728\n",
      "Epochs:  24 ; Loss:  0.008889122866094112\n",
      "Epochs:  25 ; Loss:  0.008117938414216042\n",
      "Epochs:  26 ; Loss:  0.007420829031616449\n",
      "Epochs:  27 ; Loss:  0.006791636347770691\n",
      "Epochs:  28 ; Loss:  0.006224572658538818\n",
      "Epochs:  29 ; Loss:  0.005714216269552708\n",
      "Epochs:  30 ; Loss:  0.005255502182990313\n",
      "Epochs:  31 ; Loss:  0.0048437160439789295\n",
      "Epochs:  32 ; Loss:  0.00447448343038559\n",
      "Epochs:  33 ; Loss:  0.004143756814301014\n",
      "Epochs:  34 ; Loss:  0.003847802523523569\n",
      "Epochs:  35 ; Loss:  0.0035831877030432224\n",
      "Epochs:  36 ; Loss:  0.003346762852743268\n",
      "Epochs:  37 ; Loss:  0.003135648323222995\n",
      "Epochs:  38 ; Loss:  0.0029472189489752054\n",
      "Epochs:  39 ; Loss:  0.002779085887596011\n",
      "Epochs:  40 ; Loss:  0.002629081951454282\n",
      "Epochs:  41 ; Loss:  0.002495246008038521\n",
      "Epochs:  42 ; Loss:  0.002375807147473097\n",
      "Epochs:  43 ; Loss:  0.002269170945510268\n",
      "Epochs:  44 ; Loss:  0.002173902466893196\n",
      "Epochs:  45 ; Loss:  0.0020887162536382675\n",
      "Epochs:  46 ; Loss:  0.002012460958212614\n",
      "Epochs:  47 ; Loss:  0.0019441073527559638\n",
      "Epochs:  48 ; Loss:  0.001882738433778286\n",
      "Epochs:  49 ; Loss:  0.0018275369657203555\n",
      "Epochs:  50 ; Loss:  0.0017777772154659033\n",
      "Epochs:  51 ; Loss:  0.00173281435854733\n",
      "Epochs:  52 ; Loss:  0.0016920772613957524\n",
      "Epochs:  53 ; Loss:  0.0016550605650991201\n",
      "Epochs:  54 ; Loss:  0.0016213174676522613\n",
      "Epochs:  55 ; Loss:  0.0015904533211141825\n",
      "Epochs:  56 ; Loss:  0.0015621206257492304\n",
      "Epochs:  57 ; Loss:  0.0015360132092610002\n",
      "Epochs:  58 ; Loss:  0.0015118608716875315\n",
      "Epochs:  59 ; Loss:  0.001489427755586803\n",
      "Epochs:  60 ; Loss:  0.001468505011871457\n",
      "Epochs:  61 ; Loss:  0.001448910334147513\n",
      "Epochs:  62 ; Loss:  0.0014304841170087457\n",
      "Epochs:  63 ; Loss:  0.0014130858471617103\n",
      "Epochs:  64 ; Loss:  0.0013965930556878448\n",
      "Epochs:  65 ; Loss:  0.0013808985240757465\n",
      "Epochs:  66 ; Loss:  0.001365908537991345\n",
      "Epochs:  67 ; Loss:  0.001351541723124683\n",
      "Epochs:  68 ; Loss:  0.0013377262512221932\n",
      "Epochs:  69 ; Loss:  0.0013244000729173422\n",
      "Epochs:  70 ; Loss:  0.0013115095207467675\n",
      "Epochs:  71 ; Loss:  0.0012990070972591639\n",
      "Epochs:  72 ; Loss:  0.0012868518242612481\n",
      "Epochs:  73 ; Loss:  0.0012750085443258286\n",
      "Epochs:  74 ; Loss:  0.0012634462909772992\n",
      "Epochs:  75 ; Loss:  0.00125213828869164\n",
      "Epochs:  76 ; Loss:  0.0012410611379891634\n",
      "Epochs:  77 ; Loss:  0.0012301953975111246\n",
      "Epochs:  78 ; Loss:  0.0012195233721286058\n",
      "Epochs:  79 ; Loss:  0.0012090301606804132\n",
      "Epochs:  80 ; Loss:  0.0011987031903117895\n",
      "Epochs:  81 ; Loss:  0.0011885312851518393\n",
      "Epochs:  82 ; Loss:  0.001178504666313529\n",
      "Epochs:  83 ; Loss:  0.0011686155339702964\n",
      "Epochs:  84 ; Loss:  0.0011588565539568663\n",
      "Epochs:  85 ; Loss:  0.0011492219055071473\n",
      "Epochs:  86 ; Loss:  0.0011397064663469791\n",
      "Epochs:  87 ; Loss:  0.0011303058126941323\n",
      "Epochs:  88 ; Loss:  0.0011210161028429866\n",
      "Epochs:  89 ; Loss:  0.0011118340771645308\n",
      "Epochs:  90 ; Loss:  0.0011027570581063628\n",
      "Epochs:  91 ; Loss:  0.001093782833777368\n",
      "Epochs:  92 ; Loss:  0.0010849089594557881\n",
      "Epochs:  93 ; Loss:  0.001076134038157761\n",
      "Epochs:  94 ; Loss:  0.0010674563236534595\n",
      "Epochs:  95 ; Loss:  0.0010588746517896652\n",
      "Epochs:  96 ; Loss:  0.0010503879748284817\n",
      "Epochs:  97 ; Loss:  0.0010419952450320125\n",
      "Epochs:  98 ; Loss:  0.0010336951818317175\n",
      "Epochs:  99 ; Loss:  0.0010254874359816313\n",
      "Epochs:  100 ; Loss:  0.0010173709597438574\n",
      "Epochs:  101 ; Loss:  0.0010093454038724303\n",
      "Epochs:  102 ; Loss:  0.0010014098370447755\n",
      "Epochs:  103 ; Loss:  0.0009935636771842837\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     33\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(epochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m())\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#Plot loss function\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "loss_epoch=[]\n",
    "loss_values = []\n",
    "loss=1\n",
    "epochs=0\n",
    "\n",
    "print(\"Epochs    Loss\")\n",
    "\n",
    "while(loss>tol):\n",
    "    epochs=epochs+1\n",
    "    scheduler.step()\n",
    "    \n",
    "    for x_batch, y_batch in loader:\n",
    "        # Forward pass\n",
    "        x_batch= torch.nn.Sequential(torch.nn.Unflatten(1, (1,80,80)))(x_batch)\n",
    "        y_pred=model(x_batch)        \n",
    "        loss=torch.nn.functional.mse_loss(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"1 batch\")\n",
    "    \n",
    "    loss_epoch.append(epochs)\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if epochs%1==0:\n",
    "        print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "        \n",
    "    loss=loss.item()\n",
    "\n",
    "print(epochs, \"    \", loss.item())\n",
    "\n",
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9dbba",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append name with time\n",
    "from datetime import datetime\n",
    "ct=datetime.now()\n",
    "ctime=\"_\"+str(ct.year)+str(ct.month)+str(ct.day)+\"_\"+str(ct.hour)+str(ct.minute)+str(ct.second)\n",
    "PATH=\"./result/\"+PATH+ctime+\".pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.semilogy()\n",
    "plt.savefig(PATH+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d43359",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_net=torch.jit.trace(model, (torch.randn(1, 1, 80,80)).to(device))\n",
    "traced_net.to(torch.float64)\n",
    "torch.jit.save(traced_net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae9781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
