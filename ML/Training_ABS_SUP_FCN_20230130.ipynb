{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e43f9",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad5224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:1') #先調1再調0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0994207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe6f063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENCHOU\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:120: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34dbfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8c68f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1157f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "data_in=np.loadtxt('./data/preserved/input_div_U_2_1s.dat')\n",
    "data_out=np.loadtxt('./data/preserved/output_P_1s.dat')\n",
    "x_in=torch.Tensor(data_in)\n",
    "y_in=torch.Tensor(data_out)\n",
    "x_in=x_in.to(device)\n",
    "y_in=y_in.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849bbccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 6400])\n",
      "torch.Size([1000, 6400])\n"
     ]
    }
   ],
   "source": [
    "x=x_in\n",
    "y=y_in\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c5516",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534a75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create model 建立model習慣建立class\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, A, B, C, D, E, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear_1=torch.nn.Linear(D_in, A)\n",
    "        self.linear_2=torch.nn.Linear(A, B)\n",
    "        self.linear_4=torch.nn.Linear(B, C)\n",
    "        self.linear_5=torch.nn.Linear(C, D)\n",
    "        self.linear_6=torch.nn.Linear(D, E)\n",
    "        self.linear_3=torch.nn.Linear(E, D_out)\n",
    "    \n",
    "    # Step 3. Forward pass-1/2    # Step 4. Backward pass-1/2\n",
    "    def forward(self, x):\n",
    "        a=self.linear_1(x)\n",
    "        a_relu=torch.nn.functional.relu(a) #為何activation and hidden layer 的實現方式不同\n",
    "        b=self.linear_2(a_relu) \n",
    "        b_relu=torch.nn.functional.relu(b)\n",
    "        c=self.linear_4(b_relu) \n",
    "        c_relu=torch.nn.functional.relu(c)\n",
    "        d=self.linear_5(c_relu) \n",
    "        d_relu=torch.nn.functional.relu(d)\n",
    "        e=self.linear_6(d_relu) \n",
    "        e_relu=torch.nn.functional.relu(e)\n",
    "        y_pred=self.linear_3(e_relu) \n",
    "        return y_pred\n",
    "    \n",
    "model= TwoLayerNet(D_in=6400, A=1000, B=1000, C=1000, D=1000, E=1000, D_out=6400)\n",
    "model=model.to(device) #這行是什麼意思? A:将模型加载到相应的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd496d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(TensorDataset(x, y), batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42a038",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3229b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687717dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d34a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs    Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENCHOU\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  1 ; Loss:  0.07601392269134521\n",
      "Epochs:  2 ; Loss:  0.06662115454673767\n",
      "Epochs:  3 ; Loss:  0.03603389114141464\n",
      "Epochs:  4 ; Loss:  0.014170109294354916\n",
      "Epochs:  5 ; Loss:  0.030147872865200043\n",
      "Epochs:  6 ; Loss:  0.0024728174321353436\n",
      "Epochs:  7 ; Loss:  0.0083074402064085\n",
      "Epochs:  8 ; Loss:  0.00784623995423317\n",
      "Epochs:  9 ; Loss:  0.004549754783511162\n",
      "Epochs:  10 ; Loss:  0.003448835574090481\n",
      "Epochs:  11 ; Loss:  0.002139363205060363\n",
      "Epochs:  12 ; Loss:  0.0016586406854912639\n",
      "Epochs:  13 ; Loss:  0.001904762932099402\n",
      "Epochs:  14 ; Loss:  0.0018461972940713167\n",
      "Epochs:  15 ; Loss:  0.001542054582387209\n",
      "Epochs:  16 ; Loss:  0.001540126628242433\n",
      "Epochs:  17 ; Loss:  0.001391722122207284\n",
      "Epochs:  18 ; Loss:  0.0009845265885815024\n",
      "Epochs:  19 ; Loss:  0.0010230308398604393\n",
      "Epochs:  20 ; Loss:  0.0031440092716366053\n",
      "Epochs:  21 ; Loss:  0.001609540544450283\n",
      "Epochs:  22 ; Loss:  0.00048603309551253915\n",
      "Epochs:  23 ; Loss:  0.0010710720671340823\n",
      "Epochs:  24 ; Loss:  0.0016355467960238457\n",
      "Epochs:  25 ; Loss:  0.0015624798834323883\n",
      "Epochs:  26 ; Loss:  0.0010392036056146026\n",
      "Epochs:  27 ; Loss:  0.0004826234362553805\n",
      "Epochs:  28 ; Loss:  0.0008076020749285817\n",
      "Epochs:  29 ; Loss:  0.0010103731183335185\n",
      "Epochs:  30 ; Loss:  0.0012973754201084375\n",
      "Epochs:  31 ; Loss:  0.0013945340178906918\n",
      "Epochs:  32 ; Loss:  0.002357947174459696\n",
      "Epochs:  33 ; Loss:  0.0005573630915023386\n",
      "Epochs:  34 ; Loss:  0.0016048516845330596\n",
      "Epochs:  35 ; Loss:  0.002151723252609372\n",
      "Epochs:  36 ; Loss:  0.0016453440766781569\n",
      "Epochs:  37 ; Loss:  0.0006200333591550589\n",
      "Epochs:  38 ; Loss:  0.0007156970095820725\n",
      "Epochs:  39 ; Loss:  0.0011834934120997787\n",
      "Epochs:  40 ; Loss:  0.002535745268687606\n",
      "Epochs:  41 ; Loss:  0.0017890270100906491\n",
      "Epochs:  42 ; Loss:  0.001385173061862588\n",
      "Epochs:  43 ; Loss:  0.0012087126960977912\n",
      "Epochs:  44 ; Loss:  0.0004928079433739185\n",
      "Epochs:  45 ; Loss:  0.0028195888735353947\n",
      "Epochs:  46 ; Loss:  0.0026060896925628185\n",
      "Epochs:  47 ; Loss:  0.0006693535833619535\n",
      "Epochs:  48 ; Loss:  0.002534368773922324\n",
      "Epochs:  49 ; Loss:  0.003176453523337841\n",
      "Epochs:  50 ; Loss:  0.0020694686099886894\n",
      "Epochs:  51 ; Loss:  0.0024878063704818487\n",
      "Epochs:  52 ; Loss:  0.0017258509760722518\n",
      "Epochs:  53 ; Loss:  0.0023259196896106005\n",
      "Epochs:  54 ; Loss:  0.0006349010509438813\n",
      "Epochs:  55 ; Loss:  0.0017740168841555715\n",
      "Epochs:  56 ; Loss:  0.0008392013260163367\n",
      "Epochs:  57 ; Loss:  0.0008932726923376322\n",
      "Epochs:  58 ; Loss:  0.0019846949726343155\n",
      "Epochs:  59 ; Loss:  0.0004311388765927404\n",
      "Epochs:  60 ; Loss:  0.002063881605863571\n",
      "Epochs:  61 ; Loss:  0.0010878157336264849\n",
      "Epochs:  62 ; Loss:  0.0004093999741598964\n",
      "Epochs:  63 ; Loss:  0.0009509362862445414\n",
      "Epochs:  64 ; Loss:  0.0025510964915156364\n",
      "Epochs:  65 ; Loss:  0.0012997669400647283\n",
      "Epochs:  66 ; Loss:  0.0015294540207833052\n",
      "Epochs:  67 ; Loss:  0.0019997707568109035\n",
      "Epochs:  68 ; Loss:  0.0018560771131888032\n",
      "Epochs:  69 ; Loss:  0.0011674180859699845\n",
      "Epochs:  70 ; Loss:  0.001825164770707488\n",
      "Epochs:  71 ; Loss:  0.0007822561892680824\n",
      "Epochs:  72 ; Loss:  0.0013657662784680724\n",
      "Epochs:  73 ; Loss:  0.00392785482108593\n",
      "Epochs:  74 ; Loss:  0.001467016525566578\n",
      "Epochs:  75 ; Loss:  0.0010475805029273033\n",
      "Epochs:  76 ; Loss:  0.002457387512549758\n",
      "Epochs:  77 ; Loss:  0.0012424037558957934\n",
      "Epochs:  78 ; Loss:  0.0015452620573341846\n",
      "Epochs:  79 ; Loss:  0.0012711788294836879\n",
      "Epochs:  80 ; Loss:  0.0011772949947044253\n",
      "Epochs:  81 ; Loss:  0.001607444486580789\n",
      "Epochs:  82 ; Loss:  0.004351163748651743\n",
      "Epochs:  83 ; Loss:  0.0017672566464170814\n",
      "Epochs:  84 ; Loss:  0.0009842256549745798\n",
      "Epochs:  85 ; Loss:  0.0026769733522087336\n",
      "Epochs:  86 ; Loss:  0.0012248818529769778\n",
      "Epochs:  87 ; Loss:  0.0013004374923184514\n",
      "Epochs:  88 ; Loss:  0.0014397915219888091\n",
      "Epochs:  89 ; Loss:  0.001831177854910493\n",
      "Epochs:  90 ; Loss:  0.0011024888372048736\n",
      "Epochs:  91 ; Loss:  0.0053063626401126385\n",
      "Epochs:  92 ; Loss:  0.002073985291644931\n",
      "Epochs:  93 ; Loss:  0.0010438868775963783\n",
      "Epochs:  94 ; Loss:  0.0008303405484184623\n",
      "Epochs:  95 ; Loss:  0.0014077929081395268\n",
      "Epochs:  96 ; Loss:  0.001518484321422875\n",
      "Epochs:  97 ; Loss:  0.0005315631278790534\n",
      "Epochs:  98 ; Loss:  0.0026289685629308224\n",
      "Epochs:  99 ; Loss:  0.002256638603284955\n",
      "Epochs:  100 ; Loss:  0.001356413122266531\n",
      "Epochs:  101 ; Loss:  0.002487560734152794\n",
      "Epochs:  102 ; Loss:  0.0010369826341047883\n",
      "Epochs:  103 ; Loss:  0.001164671964943409\n",
      "Epochs:  104 ; Loss:  0.0008487437735311687\n",
      "Epochs:  105 ; Loss:  0.0013486295938491821\n",
      "Epochs:  106 ; Loss:  0.0010319905122742057\n",
      "Epochs:  107 ; Loss:  0.0011373170418664813\n",
      "Epochs:  108 ; Loss:  0.0023230083752423525\n",
      "Epochs:  109 ; Loss:  0.0015661035431548953\n",
      "Epochs:  110 ; Loss:  0.002077717101201415\n",
      "Epochs:  111 ; Loss:  4.0347149479202926e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     32\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(epochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m())\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#Plot loss function\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "loss_epoch=[]\n",
    "loss_values = []\n",
    "loss=1\n",
    "epochs=0\n",
    "\n",
    "print(\"Epochs    Loss\")\n",
    "\n",
    "while(loss>tol):\n",
    "    epochs=epochs+1\n",
    "    scheduler.step()\n",
    "    \n",
    "    for x_batch, y_batch in loader:\n",
    "        # Forward pass\n",
    "        y_pred=model(x_batch)        \n",
    "        loss=torch.nn.functional.mse_loss(y_pred, x_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"1 batch\")\n",
    "    \n",
    "    loss_epoch.append(epochs)\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if epochs%1==0:\n",
    "        print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "        \n",
    "    loss=loss.item()\n",
    "\n",
    "print(epochs, \"    \", loss.item())\n",
    "\n",
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9dbba",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea4f7897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d43359",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f441f368",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [3, 1, 3, 3], but got 2-dimensional input of size [1, 6400] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m PATH\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_jit_uns_cnn_3.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m traced_net\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m traced_net\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39msave(traced_net, PATH)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\jit\\_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    757\u001b[0m ):\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    759\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    760\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m         _module_class,\n\u001b[0;32m    768\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\jit\\_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    954\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[0;32m    956\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m--> 958\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1090\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1090\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except the batch dimension\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1090\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1090\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [3, 1, 3, 3], but got 2-dimensional input of size [1, 6400] instead"
     ]
    }
   ],
   "source": [
    "device=torch.device('cpu')\n",
    "model=model.to(device)\n",
    "PATH= \"ABS_SUP_FCN_TEST.pth\"\n",
    "traced_net=torch.jit.trace(model, (torch.randn(1,6400)).to(device))\n",
    "traced_net.to(torch.float64)\n",
    "torch.jit.save(traced_net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b811b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_net=torch.jit.trace(model, (torch.randn(1, 1, 80,80)).to(device))\n",
    "traced_net.to(torch.float64)\n",
    "torch.jit.save(traced_net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807c98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
