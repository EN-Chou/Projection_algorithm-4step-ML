{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e43f9",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device check(CFDLab)\n",
    "device=torch.device('cuda:1') #先調1再調0\n",
    "print(torch.cuda.is_available())\n",
    "x=torch.randn(100).to(device) # Gives warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a358a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0') # Fix warning\n",
    "x=torch.randn(100).to(device) # No warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device check(my pc)\n",
    "device=torch.device('cpu')\n",
    "print(torch.cuda.is_available())\n",
    "x=torch.randn(100).to(device) # No warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262401a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b237a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=100 #batchsize\n",
    "opt=1 # optimizer\n",
    "tol=1e-8 # tolerance\n",
    "ch=[1, 3, 3, 3, 3, 1] #model layout\n",
    "pad=[0, 0, 0, 0, 0]\n",
    "PATH= \"DEL_SUP_CNN_TEST\" # model name, saved as.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8c68f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "data_in=np.loadtxt('./data/preserved/input_div_U_2_1s.dat')\n",
    "data_out=np.loadtxt('./data/preserved/output_P_1s.dat')\n",
    "x_in=torch.Tensor(data_in)\n",
    "y_in=torch.Tensor(data_out)\n",
    "\n",
    "x_in=x_in[1:]-x_in[:-1]\n",
    "y_in=y_in[1:]-y_in[:-1]\n",
    "\n",
    "x_in=x_in.to(device)\n",
    "y_in=y_in.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bbccf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=x_in\n",
    "y=y_in\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(TensorDataset(x, y), batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c5516",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, channel_1, channel_2, channel_3, channel_4, channel_5, kernel_dim):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, channel_1, kernel_dim, padding=pad[0])\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_dim, padding=pad[1])\n",
    "        self.conv3 = nn.Conv2d(channel_2, channel_3, kernel_dim, padding=pad[2])\n",
    "        self.conv4 = nn.Conv2d(channel_3, channel_4, kernel_dim, padding=pad[3])\n",
    "        self.conv5 = nn.Conv2d(channel_4, channel_5, kernel_dim, padding=pad[4])\n",
    "        # an affine operation: y = Wx + b\n",
    "        lin_d=80-(pad[0]+pad[1]+pad[2]+pad[3]+pad[4])*2\n",
    "        self.fc1 = nn.Linear(70*70*channel_5, 6400)  # 78*78 from image dimension\n",
    "        #self.fc2 = nn.Linear(1000, 1000)\n",
    "        #self.fc3 = nn.Linear(1000, 6400)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet(channel_1=ch[1], channel_2=ch[2], channel_3=ch[3], channel_4=ch[4], channel_5=1, kernel_dim=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42a038",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687717dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt==0:\n",
    "    optimizer=torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "elif opt==1:\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_epoch=[]\n",
    "loss_values = []\n",
    "loss=1\n",
    "epochs=0\n",
    "\n",
    "print(\"Epochs    Loss\")\n",
    "\n",
    "while(loss>tol):\n",
    "    epochs=epochs+1\n",
    "    scheduler.step()\n",
    "    \n",
    "    for x_batch, y_batch in loader:\n",
    "        # Forward pass\n",
    "        x_batch= torch.nn.Sequential(torch.nn.Unflatten(1, (1,80,80)))(x_batch)\n",
    "        y_pred=model(x_batch)        \n",
    "        loss=torch.nn.functional.mse_loss(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"1 batch\")\n",
    "    \n",
    "    loss_epoch.append(epochs)\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if epochs%1==0:\n",
    "        print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "        \n",
    "    loss=loss.item()\n",
    "\n",
    "print(epochs, \"    \", loss.item())\n",
    "\n",
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9dbba",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append name with time\n",
    "from datetime import datetime\n",
    "ct=datetime.now()\n",
    "ctime=str(ct.year)+str(ct.month)+str(ct.day)+\"_\"+str(ct.hour)+str(ct.minute)+str(ct.second)\n",
    "PATH=PATH+\"_\"+ctime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.semilogy()\n",
    "plt.savefig(\"./result/\"+PATH+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d43359",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_net=torch.jit.trace(model, (torch.randn(1, 1, 80,80)).to(device))\n",
    "traced_net.to(torch.float64)\n",
    "torch.jit.save(traced_net, \"./result/\"+PATH+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save information\n",
    "with open(\"./result/\"+PATH+'.txt', 'w') as f:\n",
    "        f.write('# Model info\\n')\n",
    "        f.write('Model: '+ PATH+'\\n')\n",
    "        f.write('ID: '+ ctime +'\\n')\n",
    "        f.write('Data format: '+ 'Delta' +'\\n')\n",
    "        f.write('Learning method: Supervised'+'\\n')\n",
    "        f.write('Model: CNN'+'\\n')\n",
    "        f.write('residual: '+str(tol)+'\\n')\n",
    "        f.write('batch_size: '+str(batch)+'\\n')\n",
    "        f.write('epochs: '+str(epochs)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
